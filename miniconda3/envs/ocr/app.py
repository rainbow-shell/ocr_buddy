from flask import Flask, request, render_template, jsonify, send_file
from pdf2image import convert_from_path
import pytesseract
import os
import tempfile
import uuid
from werkzeug.utils import secure_filename
import io
from openai import OpenAI

app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size

UPLOAD_FOLDER = 'uploads'
OUTPUT_FOLDER = 'outputs'
ALLOWED_EXTENSIONS = {'pdf'}

# Create directories if they don't exist
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(OUTPUT_FOLDER, exist_ok=True)

# Initialize OpenAI client (requires OPENAI_API_KEY environment variable)
client = OpenAI(
    api_key=os.environ.get("OPENAI_API_KEY")
)

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def extract_text_from_pdf(pdf_path):
    """Extract text from PDF using OCR"""
    try:
        # Convert PDF pages to images
        pages = convert_from_path(pdf_path, dpi=300)
        
        # Run OCR and collect text
        text = "\n".join(pytesseract.image_to_string(page) for page in pages)
        
        return text
    except Exception as e:
        raise Exception(f"OCR processing failed: {str(e)}")

def split_text_into_chunks(text, max_chars=10000):
    """Split text into chunks of maximum characters, trying to break at sentence boundaries"""
    if len(text) <= max_chars:
        return [text]
    
    chunks = []
    current_chunk = ""
    
    # Split by paragraphs first (double newlines)
    paragraphs = text.split('\n\n')
    
    for paragraph in paragraphs:
        # If adding this paragraph would exceed the limit
        if len(current_chunk) + len(paragraph) + 2 > max_chars:
            if current_chunk:
                chunks.append(current_chunk.strip())
                current_chunk = ""
            
            # If single paragraph is too long, split by sentences
            if len(paragraph) > max_chars:
                sentences = paragraph.split('. ')
                for i, sentence in enumerate(sentences):
                    if i < len(sentences) - 1:  # Add period back except for last sentence
                        sentence += '.'
                    
                    if len(current_chunk) + len(sentence) + 1 > max_chars:
                        if current_chunk:
                            chunks.append(current_chunk.strip())
                            current_chunk = ""
                    
                    current_chunk += sentence + (" " if i < len(sentences) - 1 else "")
            else:
                current_chunk = paragraph
        else:
            current_chunk += ("\n\n" if current_chunk else "") + paragraph
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks

def cleanup_text_chunk(chunk):
    """Clean up a single chunk of OCR text using OpenAI API"""
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {
                "role": "system",
                "content": """You are provided a block of text (the "user message") that has been generated by an OCR (optical character recognition) application scanning a PDF file. Your task is to improve the formatting and readability of this text, restoring its appearance to match as closely as possible how it likely appeared in the original document. You should also remove any artifacts and errors introduced by the OCR process or by the PDF conversion that do not belong to the original text, such as odd line breaks, hyphenation at line endings, incorrect characters, misplaced page numbers or headers/footers, and any irrelevant symbols or marks.

IMPORTANT: This text may be part of a larger document. Do not add introductory or concluding remarks. Simply clean and format the provided text section.

# Steps

1. **Analyze** the provided text, identifying issues introduced by OCR and PDF conversion, such as:
   - Misplaced or broken words and lines
   - Spurious hyphens at line endings
   - Incorrect special characters or symbols
   - Inconsistent or inappropriate paragraph breaks
   - Page numbers, footers/headers erroneously inserted in the text
2. **Remove or correct** all artifacts and errors attributable to OCR or PDF processing.
3. **Reconstruct the text** for optimal readability, restoring paragraphs, sentences, and formatting in a way that best reflects the structure and flow of the likely original document.
4. **Review your output** to ensure clarity, coherence, and that all artifacts have been removed.

# Output Format

Respond with only the improved text, in paragraph form, preserving intended structure (such as headings, paragraphs, and lists) where confidently inferrable. Do NOT add commentary or summaries.

# Notes

- Be careful not to remove content that clearly belongs to the original document.
- Use best judgment when reconstructing ambiguous segments.
- If the structure is unclear, prioritize coherence and readability.
- This may be a fragment of a larger document, so don't add connecting text.

**Reminder**: Improve the formatting and readability of scanned/OCR text by analyzing for artifacts, removing errors, and restoring natural text flow. Output only the corrected, improved text."""
            },
            {
                "role": "user",
                "content": chunk
            }
        ],
        temperature=0.3,
        max_tokens=4000
    )
    
    return response.choices[0].message.content.strip()

def cleanup_ocr_text(raw_text):
    """Clean up OCR text using OpenAI API, splitting into chunks if necessary"""
    try:
        # Check if API key is available
        if not os.environ.get("OPENAI_API_KEY"):
            raise Exception("OpenAI API key not found. Please set OPENAI_API_KEY environment variable.")
        
        # Split text into chunks if it's too long
        chunks = split_text_into_chunks(raw_text, max_chars=10000)
        
        # If only one chunk, process normally
        if len(chunks) == 1:
            return cleanup_text_chunk(chunks[0])
        
        # Process multiple chunks
        cleaned_chunks = []
        for i, chunk in enumerate(chunks):
            try:
                cleaned_chunk = cleanup_text_chunk(chunk)
                cleaned_chunks.append(cleaned_chunk)
            except Exception as chunk_error:
                # If a chunk fails, add the original chunk to maintain content
                print(f"Warning: Failed to clean chunk {i+1}: {str(chunk_error)}")
                cleaned_chunks.append(chunk)
        
        # Recombine chunks with double newlines to maintain paragraph separation
        return "\n\n".join(cleaned_chunks)
        
    except Exception as e:
        raise Exception(f"OpenAI API cleanup failed: {str(e)}")

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/upload', methods=['POST'])
def upload_file():
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'No file provided'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'No file selected'}), 400
        
        if not allowed_file(file.filename):
            return jsonify({'error': 'Only PDF files are allowed'}), 400
        
        # Generate unique filename
        file_id = str(uuid.uuid4())
        filename = secure_filename(file.filename)
        upload_path = os.path.join(UPLOAD_FOLDER, f"{file_id}_{filename}")
        
        # Save uploaded file
        file.save(upload_path)
        
        # Extract text using OCR
        extracted_text = extract_text_from_pdf(upload_path)
        
        # Save extracted text
        output_filename = f"{file_id}_output.txt"
        output_path = os.path.join(OUTPUT_FOLDER, output_filename)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(extracted_text)
        
        # Clean up uploaded PDF
        os.remove(upload_path)
        
        return jsonify({
            'success': True,
            'message': 'OCR processing completed successfully',
            'output_file': output_filename,
            'extracted_text': extracted_text
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/save/<filename>', methods=['POST'])
def save_file(filename):
    try:
        file_path = os.path.join(OUTPUT_FOLDER, filename)
        if not os.path.exists(file_path):
            return jsonify({'error': 'File not found'}), 404
        
        data = request.get_json()
        if not data or 'text' not in data:
            return jsonify({'error': 'No text content provided'}), 400
        
        # Save the updated text
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(data['text'])
        
        return jsonify({
            'success': True,
            'message': 'File saved successfully'
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/cleanup', methods=['POST'])
def cleanup_text():
    try:
        data = request.get_json()
        if not data or 'text' not in data:
            return jsonify({'error': 'No text content provided'}), 400
        
        raw_text = data['text']
        if not raw_text.strip():
            return jsonify({'error': 'Empty text provided'}), 400
        
        # Clean up the text using OpenAI
        cleaned_text = cleanup_ocr_text(raw_text)
        
        return jsonify({
            'success': True,
            'message': 'Text cleanup completed successfully',
            'cleaned_text': cleaned_text
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/download/<filename>')
def download_file(filename):
    try:
        file_path = os.path.join(OUTPUT_FOLDER, filename)
        if not os.path.exists(file_path):
            return jsonify({'error': 'File not found'}), 404
        
        return send_file(file_path, as_attachment=True, download_name=filename)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5001)